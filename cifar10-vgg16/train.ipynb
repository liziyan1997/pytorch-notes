{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 10\n",
    "LR_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg16网络结构，输入图像大小变化： 32-> 16->  8->  4->  2->  1\n",
    "# vgg16网络结构，输入通道大小变化：  3-> 64->128->256->512->512\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            #1\n",
    "            nn.Conv2d(3,64,kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            #2\n",
    "            nn.Conv2d(64,64,kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            #3\n",
    "            nn.Conv2d(64,128,kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            #4\n",
    "            nn.Conv2d(128,128,kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            #5\n",
    "            nn.Conv2d(128,256,kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            #6\n",
    "            nn.Conv2d(256,256,kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            #7\n",
    "            nn.Conv2d(256,256,kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            #8\n",
    "            nn.Conv2d(256,512,kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            #9\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            #10\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            #11\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            #12\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            #13\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.AvgPool2d(kernel_size=1,stride=1),\n",
    "            )\n",
    "        self.classifier = nn.Sequential(\n",
    "            #14\n",
    "            nn.Linear(512,4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            #15\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            #16\n",
    "            nn.Linear(4096,num_classes),\n",
    "            )\n",
    "        #self.classifier = nn.Linear(512, 10)\n",
    " \n",
    "    def forward(self, x):\n",
    "        out = self.features(x) \n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4), #先四周填充0，再把图像随机裁剪成32*32\n",
    "    transforms.RandomHorizontalFlip(),  #图像一半的概率翻转，一半的概率不翻转\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n",
    "    ])\n",
    " \n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=0)\n",
    " \n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=0)\n",
    "#Cifar-10的标签\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "print(trainset.__len__())\n",
    "print(len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型定义 VGG16\n",
    "net = VGG16().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数和优化方式\n",
    "criterion = nn.CrossEntropyLoss()   # 损失函数使用交叉熵\n",
    "# CrossEntropyLoss会计算出每一个样本的交叉熵并在batchsize上取平均，返回的是一个标量数值\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR_RATE, momentum=0.9, weight_decay=5e-4) # 优化方式为mini-batch momentum-SGD，并采用L2正则化（权重衰减）"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0, EPOCH):\n",
    "    print('\\nEpoch: %d' % (epoch + 1))\n",
    "    #开始训练\n",
    "    net.train()\n",
    "    #总损失\n",
    "    sum_loss = 0.0\n",
    "    #准确率\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "\n",
    "    for i, data in enumerate(trainloader):\n",
    "        #准备数据\n",
    "        length = len(trainloader)           # 数据大小\n",
    "        inputs, labels = data               # 取出数据\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()               # 梯度初始化为零（因为一个batch的loss关于weight的导数是所有sample的loss关于weight的导数的累加和）\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)               # 前向传播求出预测值\n",
    "        loss = criterion(outputs, labels)   # 求loss\n",
    "        loss.backward()                     # 反向传播求梯度\n",
    "        optimizer.step()                    # 更新参数\n",
    "\n",
    "        # 每一个batch输出对应的损失loss和准确率accuracy\n",
    "        sum_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)           # 返回每一行中最大值的那个元素，且返回其索引\n",
    "        # predicted为batchsize*1的tensor，其中对应值为对应输入的预测结果\n",
    "        total += labels.size(0)                             # 记录一共使用了多少个样本\n",
    "        accuracy += predicted.eq(labels.data).cpu().sum()   # 预测值和真实值进行比较，将数据放到cpu上并且求和\n",
    "\n",
    "        print('[epoch:%d, iter:%d] Loss: %.03f | Acc: %.3f%% '\n",
    "                         % (epoch + 1, (i + 1 + epoch * length), sum_loss / (i + 1), 100. * accuracy / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './train_ipynb.pth'\n",
    "torch.save(net.state_dict(),PATH)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        accuracy += predicted.eq(labels.data).cpu().sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %.2f %%' % (\n",
    "    100 * accuracy / total))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}